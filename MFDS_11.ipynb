{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fbd4d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 2: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 3: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 4: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 5: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 6: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 7: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 8: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 9: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 10: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 11: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 12: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 13: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 14: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 15: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 16: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 17: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 18: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 19: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 20: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 21: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 22: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 23: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 24: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 25: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 26: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 27: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 28: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 29: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 30: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 31: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 32: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 33: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 34: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 35: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 36: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 37: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 38: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 39: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 40: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 41: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 42: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 43: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 44: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 45: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 46: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 47: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 48: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 49: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 50: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 51: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 52: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 53: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 54: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 55: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 56: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 57: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 58: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 59: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 60: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 61: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 62: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 63: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 64: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 65: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 66: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 67: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 68: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 69: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 70: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 71: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 72: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 73: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 74: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 75: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 76: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 77: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 78: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 79: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 80: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 81: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 82: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 83: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 84: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 85: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 86: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 87: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 88: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 89: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 90: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 91: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 92: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 93: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 94: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 95: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 96: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 97: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 98: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 99: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 100: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 101: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 102: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 103: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 104: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 105: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 106: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 107: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 108: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 109: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 110: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 111: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 112: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 113: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 114: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 115: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 116: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 117: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 118: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 119: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 120: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 121: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 122: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 123: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 124: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 125: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 126: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 127: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 128: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 129: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 130: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 131: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 132: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 133: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 134: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 135: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 136: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 137: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 138: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 139: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 140: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 141: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 142: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 143: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 144: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 145: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 146: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 147: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 148: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 149: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 150: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 151: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 152: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 153: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 154: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 155: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 156: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 157: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 158: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 159: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 160: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 161: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 162: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 163: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 164: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 165: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 166: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 167: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 168: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 169: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 170: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 171: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 172: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 173: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 174: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 175: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 176: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 177: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 178: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 179: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 180: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 181: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 182: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 183: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 184: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 185: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 186: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 187: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 188: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 189: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 190: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 191: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 192: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 193: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 194: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 195: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 196: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 197: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 198: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 199: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 200: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 201: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 202: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 203: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 204: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 205: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 206: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 207: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 208: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 209: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 210: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 211: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 212: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 213: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 214: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 215: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 216: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 217: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 218: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 219: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 220: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 221: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 222: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 223: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 224: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 225: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 226: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 227: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 228: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 229: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 230: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 231: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 232: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 233: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 234: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 235: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 236: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 237: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 238: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 239: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 240: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 241: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 242: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 243: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 244: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 245: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 246: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 247: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 248: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 249: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 250: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 251: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 252: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 253: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 254: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 255: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 256: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 257: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 258: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 259: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 260: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 261: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 262: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 263: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 264: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 265: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 266: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 267: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 268: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 269: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 270: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 271: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 272: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 273: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 274: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 275: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 276: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 277: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 278: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 279: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 280: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 281: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 282: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 283: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 284: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 285: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 286: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 287: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 288: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 289: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 290: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 291: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 292: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 293: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 294: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 295: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 296: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 297: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 298: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 299: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 300: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 301: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 302: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 303: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 304: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 305: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 306: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 307: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 308: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 309: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 310: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 311: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 312: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 313: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 314: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 315: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 316: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 317: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 318: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 319: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 320: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 321: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 322: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 323: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 324: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 325: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 326: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 327: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 328: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 329: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 330: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 331: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 332: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 333: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 334: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 335: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 336: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 337: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 338: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 339: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 340: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 341: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 342: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 343: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 344: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 345: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 346: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 347: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 348: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 349: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 350: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 351: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 352: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 353: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 354: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 355: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 356: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 357: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 358: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 359: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 360: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 361: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 362: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 363: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 364: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 365: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 366: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 367: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 368: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 369: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 370: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 371: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 372: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 373: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 374: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 375: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 376: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 377: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 378: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 379: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 380: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 381: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 382: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 383: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 384: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 385: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 386: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 387: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 388: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 389: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 390: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 391: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 392: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 393: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 394: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 395: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 396: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 397: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 398: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 399: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 400: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 401: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 402: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 403: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 404: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 405: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 406: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 407: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 408: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 409: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 410: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 411: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 412: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 413: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 414: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 415: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 416: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 417: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 418: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 419: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 420: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 421: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 422: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 423: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 424: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 425: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 426: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 427: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 428: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 429: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 430: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 431: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 432: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 433: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 434: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 435: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 436: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 437: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 438: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 439: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 440: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 441: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 442: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 443: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 444: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 445: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 446: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 447: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 448: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 449: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 450: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 451: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 452: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 453: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 454: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 455: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 456: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 457: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 458: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 459: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 460: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 461: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 462: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 463: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 464: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 465: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 466: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 467: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 468: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 469: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 470: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 471: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 472: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 473: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 474: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 475: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 476: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 477: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 478: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 479: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 480: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 481: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 482: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 483: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 484: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 485: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 486: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 487: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 488: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 489: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 490: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 491: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 492: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 493: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 494: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 495: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 496: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 497: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 498: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 499: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 500: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 501: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 502: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 503: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 504: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 505: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 506: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 507: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 508: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 509: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 510: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 511: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 512: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 513: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 514: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 515: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 516: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 517: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 518: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 519: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 520: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 521: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 522: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 523: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 524: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 525: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 526: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 527: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 528: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 529: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 530: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 531: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 532: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 533: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 534: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 535: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 536: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 537: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 538: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 539: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 540: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 541: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 542: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 543: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 544: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 545: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 546: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 547: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 548: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 549: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 550: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 551: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 552: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 553: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 554: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 555: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 556: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 557: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 558: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 559: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 560: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 561: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 562: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 563: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 564: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 565: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 566: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 567: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 568: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 569: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 570: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 571: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 572: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 573: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 574: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 575: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 576: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 577: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 578: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 579: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 580: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 581: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 582: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 583: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 584: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 585: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 586: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 587: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 588: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 589: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 590: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 591: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 592: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 593: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 594: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 595: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 596: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 597: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 598: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 599: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 600: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 601: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 602: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 603: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 604: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 605: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 606: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 607: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 608: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 609: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 610: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 611: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 612: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 613: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 614: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 615: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 616: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 617: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 618: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 619: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 620: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 621: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 622: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 623: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 624: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 625: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 626: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 627: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 628: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 629: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 630: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 631: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 632: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 633: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 634: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 635: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 636: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 637: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 638: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 639: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 640: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 641: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 642: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 643: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 644: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 645: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 646: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 647: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 648: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 649: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 650: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 651: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 652: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 653: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 654: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 655: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 656: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 657: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 658: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 659: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 660: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 661: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 662: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 663: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 664: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 665: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 666: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 667: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 668: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 669: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 670: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 671: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 672: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 673: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 674: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 675: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 676: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 677: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 678: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 679: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 680: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 681: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 682: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 683: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 684: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 685: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 686: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 687: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 688: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 689: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 690: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 691: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 692: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 693: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 694: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 695: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 696: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 697: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 698: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 699: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 700: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 701: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 702: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 703: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 704: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 705: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 706: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 707: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 708: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 709: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 710: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 711: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 712: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 713: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 714: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 715: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 716: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 717: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 718: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 719: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 720: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 721: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 722: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 723: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 724: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 725: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 726: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 727: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 728: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 729: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 730: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 731: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 732: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 733: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 734: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 735: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 736: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 737: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 738: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 739: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 740: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 741: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 742: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 743: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 744: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 745: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 746: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 747: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 748: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 749: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 750: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 751: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 752: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 753: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 754: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 755: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 756: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 757: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 758: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 759: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 760: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 761: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 762: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 763: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 764: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 765: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 766: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 767: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 768: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 769: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 770: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 771: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 772: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 773: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 774: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 775: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 776: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 777: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 778: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 779: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 780: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 781: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 782: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 783: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 784: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 785: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 786: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 787: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 788: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 789: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 790: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 791: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 792: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 793: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 794: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 795: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 796: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 797: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 798: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 799: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 800: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 801: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 802: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 803: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 804: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 805: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 806: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 807: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 808: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 809: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 810: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 811: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 812: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 813: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 814: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 815: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 816: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 817: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 818: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 819: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 820: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 821: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 822: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 823: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 824: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 825: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 826: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 827: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 828: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 829: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 830: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 831: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 832: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 833: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 834: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 835: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 836: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 837: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 838: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 839: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 840: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 841: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 842: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 843: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 844: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 845: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 846: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 847: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 848: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 849: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 850: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 851: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 852: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 853: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 854: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 855: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 856: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 857: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 858: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 859: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 860: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 861: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 862: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 863: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 864: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 865: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 866: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 867: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 868: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 869: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 870: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 871: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 872: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 873: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 874: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 875: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 876: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 877: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 878: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 879: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 880: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 881: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 882: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 883: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 884: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 885: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 886: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 887: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 888: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 889: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 890: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 891: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 892: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 893: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 894: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 895: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 896: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 897: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 898: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 899: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 900: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 901: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 902: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 903: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 904: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 905: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 906: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 907: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 908: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 909: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 910: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 911: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 912: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 913: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 914: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 915: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 916: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 917: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 918: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 919: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 920: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 921: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 922: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 923: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 924: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 925: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 926: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 927: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 928: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 929: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 930: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 931: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 932: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 933: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 934: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 935: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 936: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 937: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 938: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 939: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 940: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 941: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 942: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 943: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 944: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 945: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 946: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 947: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 948: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 949: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 950: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 951: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 952: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 953: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 954: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 955: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 956: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 957: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 958: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 959: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 960: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 961: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 962: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 963: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 964: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 965: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 966: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 967: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 968: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 969: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 970: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 971: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 972: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 973: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 974: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 975: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 976: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 977: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 978: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 979: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 980: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 981: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 982: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 983: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 984: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 985: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 986: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 987: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 988: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 989: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 990: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 991: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 992: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 993: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 994: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 995: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 996: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 997: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 998: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 999: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1000: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1001: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1002: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1003: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1004: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1005: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1006: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1007: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1008: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1009: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1010: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1011: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1012: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1013: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1014: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1015: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1016: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1017: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1018: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1019: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1020: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1021: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1022: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1023: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1024: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1025: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1026: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1027: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1028: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1029: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1030: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1031: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1032: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1033: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1034: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1035: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1036: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1037: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1038: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1039: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1040: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1041: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1042: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1043: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1044: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1045: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1046: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1047: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1048: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1049: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1050: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1051: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1052: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1053: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1054: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1055: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1056: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1057: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1058: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1059: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1060: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1061: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1062: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1063: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1064: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1065: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1066: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1067: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1068: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1069: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1070: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1071: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1072: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1073: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1074: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1075: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1076: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1077: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1078: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1079: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1080: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1081: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1082: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1083: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1084: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1085: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1086: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1087: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1088: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1089: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1090: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1091: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1092: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1093: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1094: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1095: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1096: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1097: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1098: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1099: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1100: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1101: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1102: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1103: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1104: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1105: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1106: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1107: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1108: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1109: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1110: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1111: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1112: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1113: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1114: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1115: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1116: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1117: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1118: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1119: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1120: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1121: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1122: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1123: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1124: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1125: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1126: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1127: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1128: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1129: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1130: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1131: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1132: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1133: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1134: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1135: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1136: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1137: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1138: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1139: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1140: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1141: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1142: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1143: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1144: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1145: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1146: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1147: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1148: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1149: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1150: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1151: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1152: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1153: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1154: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1155: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1156: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1157: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1158: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1159: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1160: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1161: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1162: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1163: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1164: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1165: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1166: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1167: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1168: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1169: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1170: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1171: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1172: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1173: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1174: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1175: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1176: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1177: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1178: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1179: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1180: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1181: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1182: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1183: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1184: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1185: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1186: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1187: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1188: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1189: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1190: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1191: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1192: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1193: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1194: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1195: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1196: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1197: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1198: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1199: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1200: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1201: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1202: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1203: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1204: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1205: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1206: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1207: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1208: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1209: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1210: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1211: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1212: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1213: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1214: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1215: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1216: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1217: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1218: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1219: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1220: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1221: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1222: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1223: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1224: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1225: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1226: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1227: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1228: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1229: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1230: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1231: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1232: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1233: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1234: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1235: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1236: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1237: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1238: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1239: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1240: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1241: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1242: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1243: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1244: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1245: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1246: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1247: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1248: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1249: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1250: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1251: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1252: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1253: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1254: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1255: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1256: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1257: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1258: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1259: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1260: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1261: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1262: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1263: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1264: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1265: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1266: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1267: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1268: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1269: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1270: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1271: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1272: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1273: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1274: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1275: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1276: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1277: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1278: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1279: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1280: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1281: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1282: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1283: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1284: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1285: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1286: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1287: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1288: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1289: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1290: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1291: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1292: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1293: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1294: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1295: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1296: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1297: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1298: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1299: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1300: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1301: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1302: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1303: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1304: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1305: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1306: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1307: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1308: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1309: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1310: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1311: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1312: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1313: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1314: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1315: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1316: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1317: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1318: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1319: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1320: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1321: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1322: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1323: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1324: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1325: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1326: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1327: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1328: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1329: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1330: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1331: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1332: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1333: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1334: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1335: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1336: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1337: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1338: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1339: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1340: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1341: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1342: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1343: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1344: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1345: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1346: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1347: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1348: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1349: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1350: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1351: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1352: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1353: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1354: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1355: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1356: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1357: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1358: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1359: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1360: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1361: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1362: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1363: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1364: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1365: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1366: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1367: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1368: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1369: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1370: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1371: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1372: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1373: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1374: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1375: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1376: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1377: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1378: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1379: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1380: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1381: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1382: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1383: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1384: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1385: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1386: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1387: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1388: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1389: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1390: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1391: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1392: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1393: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1394: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1395: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1396: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1397: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1398: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1399: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1400: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1401: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1402: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1403: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1404: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1405: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1406: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1407: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1408: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1409: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1410: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1411: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1412: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1413: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1414: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1415: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1416: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1417: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1418: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1419: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1420: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1421: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1422: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1423: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1424: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1425: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1426: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1427: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1428: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1429: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1430: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1431: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1432: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1433: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1434: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1435: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1436: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1437: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1438: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1439: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1440: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1441: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1442: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1443: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1444: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1445: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1446: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1447: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1448: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1449: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1450: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1451: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1452: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1453: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1454: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1455: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1456: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1457: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1458: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1459: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1460: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1461: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1462: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1463: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1464: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1465: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1466: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1467: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1468: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1469: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1470: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1471: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1472: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1473: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1474: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1475: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1476: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1477: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1478: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1479: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1480: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1481: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1482: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1483: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1484: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1485: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1486: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1487: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1488: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1489: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1490: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1491: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1492: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1493: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1494: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1495: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1496: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1497: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1498: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1499: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n",
      "Epoch 1500: Vanilla Loss = 0.0902, Mini Batch Loss = 0.0857, Stochastic Loss = 0.0865\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate synthetic data with 1500 rows and 15 columns\n",
    "num_samples = 1500\n",
    "num_features = 15\n",
    "X = np.random.rand(num_samples, num_features)\n",
    "y = np.random.rand(num_samples, 1)\n",
    "\n",
    "# Initialize parameters\n",
    "theta = np.random.rand(num_features, 1)\n",
    "learning_rate = 0.01\n",
    "num_epochs = 1500\n",
    "\n",
    "# Vanilla Gradient Descent\n",
    "def vanilla_gradient_descent(X, y, theta, learning_rate, num_epochs):\n",
    "    for _ in range(num_epochs):\n",
    "        gradients = X.T @ (X @ theta - y) / num_samples\n",
    "        theta -= learning_rate * gradients\n",
    "    return theta\n",
    "\n",
    "# Mini Batch Gradient Descent\n",
    "def mini_batch_gradient_descent(X, y, theta, learning_rate, num_epochs, batch_size):\n",
    "    num_batches = num_samples // batch_size\n",
    "    for _ in range(num_epochs):\n",
    "        for batch_start in range(0, num_samples, batch_size):\n",
    "            batch_end = batch_start + batch_size\n",
    "            X_batch = X[batch_start:batch_end]\n",
    "            y_batch = y[batch_start:batch_end]\n",
    "            gradients = X_batch.T @ (X_batch @ theta - y_batch) / batch_size\n",
    "            theta -= learning_rate * gradients\n",
    "    return theta\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "def stochastic_gradient_descent(X, y, theta, learning_rate, num_epochs):\n",
    "    for _ in range(num_epochs):\n",
    "        for i in range(num_samples):\n",
    "            X_i = X[i:i+1]\n",
    "            y_i = y[i:i+1]\n",
    "            gradient = X_i.T @ (X_i @ theta - y_i)\n",
    "            theta -= learning_rate * gradient\n",
    "    return theta\n",
    "\n",
    "# Test the methods\n",
    "vanilla_theta = vanilla_gradient_descent(X, y, theta.copy(), learning_rate, num_epochs)\n",
    "batch_size = 32  # Optimal batch size to be determined experimentally\n",
    "mini_batch_theta = mini_batch_gradient_descent(X, y, theta.copy(), learning_rate, num_epochs, batch_size)\n",
    "stochastic_theta = stochastic_gradient_descent(X, y, theta.copy(), learning_rate, num_epochs)\n",
    "\n",
    "# Compare convergence behavior\n",
    "# You can track the loss function value over epochs and observe how it decreases.\n",
    "\n",
    "def compute_loss(X, y, theta):\n",
    "    loss = np.mean((X @ theta - y) ** 2)\n",
    "    return loss\n",
    "\n",
    "vanilla_losses = []\n",
    "mini_batch_losses = []\n",
    "stochastic_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    vanilla_loss = compute_loss(X, y, vanilla_theta)\n",
    "    mini_batch_loss = compute_loss(X, y, mini_batch_theta)\n",
    "    stochastic_loss = compute_loss(X, y, stochastic_theta)\n",
    "    \n",
    "    vanilla_losses.append(vanilla_loss)\n",
    "    mini_batch_losses.append(mini_batch_loss)\n",
    "    stochastic_losses.append(stochastic_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Vanilla Loss = {vanilla_loss:.4f}, Mini Batch Loss = {mini_batch_loss:.4f}, Stochastic Loss = {stochastic_loss:.4f}\")\n",
    "\n",
    "# Plot the convergence behavior\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(num_epochs), vanilla_losses, label='Vanilla GD')\n",
    "plt.plot(range(num_epochs), mini_batch_losses, label=f'Mini Batch GD (batch size = {batch_size})')\n",
    "plt.plot(range(num_epochs), stochastic_losses, label='Stochastic GD')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Convergence Behavior')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d7cf8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d724624e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04551be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1242d270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbd3bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
